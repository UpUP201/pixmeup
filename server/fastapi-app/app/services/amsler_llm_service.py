import re
import time
from app.utils.amsler_prompt_builder import build_amsler_prompt
from app.core.gemini_client import get_gemini_response
from app.services.rag_service import get_retrieved_knowledge  # âœ… RAG ì¶”ê°€

async def generate_amsler_comment(survey, amsler_test_list):
    print(f"ğŸ“¥ [LLM] ì•”ìŠ¬ëŸ¬ ë¶„ì„ ì‹œì‘: user_id={survey.user_id}")
    total_start = time.time()

    # 1ï¸âƒ£ ê¸°ì¡´ prompt ìƒì„±
    prompt = build_amsler_prompt(survey, amsler_test_list)
    print("ğŸ§± [Prompt] ìƒì„± ì™„ë£Œ")

    # 2ï¸âƒ£ RAG ë¬¸ì„œ ê²€ìƒ‰ ì¶”ê°€
    rag_start = time.time()
    rag_context = await get_retrieved_knowledge(
        user_id=survey.user_id,
        test_type="amsler",
        query_text=prompt
    )
    print(f"ğŸ“š [RAG] ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ ({time.time() - rag_start:.2f}s)")

    # 3ï¸âƒ£ prompt + knowledge ì¡°í•©
    enhanced_prompt = f"""{prompt}

[ì°¸ê³  ì§€ì‹]
{rag_context}

ìœ„ ê²€ì‚¬ ê²°ê³¼ì™€ ì¶”ê°€ ì§€ì‹ì„ ì°¸ê³ í•˜ì—¬ ì•”ìŠ¬ëŸ¬ ê²€ì‚¬ ê²°ê³¼ì— ëŒ€í•œ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""

    # 4ï¸âƒ£ LLM í˜¸ì¶œ
    llm_start = time.time()
    response_text = await get_gemini_response(enhanced_prompt)
    print(f"ğŸ¤– [LLM] ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ ({time.time() - llm_start:.2f}s)")

    # 5ï¸âƒ£ ì½”ë“œ ë¸”ë¡ ì œê±° + ê°œí–‰ ì œê±°
    clean_text = re.sub(r"```.*?```", "", response_text, flags=re.DOTALL).strip()
    clean_text = clean_text.replace("\n", " ").strip()

    print(f"âœ… [ì™„ë£Œ] ì „ì²´ ì†Œìš” ì‹œê°„: {time.time() - total_start:.2f}s")
    return {"comment": clean_text}
